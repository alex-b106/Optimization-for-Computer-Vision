{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b3e14d",
   "metadata": {},
   "source": [
    "# OVO Tutorial #1: Multi-Scale Image Analysis and Edge Detection\n",
    "\n",
    "In this tutorial, we'll explore:\n",
    "1. Basic image operations and homography estimation\n",
    "2. Multi-scale image analysis using image pyramids\n",
    "3. Edge detection using the Canny algorithm\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23ab9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Configure matplotlib for notebook display\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f395357",
   "metadata": {},
   "source": [
    "# Part 1: Image Basics and Homography\n",
    "## Exercise 1.1: Loading and Basic Image Properties\n",
    "\n",
    "Explore the images basic properties:\n",
    "- Display the image shape\n",
    "- Print the data type\n",
    "- Show the value range (min and max)\n",
    "- Display the image using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b89d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the grayscale image using imread and specifying that it's a grayscale image in the second argument\n",
    "gray = cv2.imread('graycat.jpg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a146c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ff2aef",
   "metadata": {},
   "source": [
    "## Exercise 1.2: Point Transformations\n",
    "\n",
    "Implement two functions:\n",
    "1. `adjust_brightness(image, beta)`: Adjusts image brightness by adding beta\n",
    "2. `adjust_contrast(image, alpha)`: Adjusts image contrast by multiplying by alpha\n",
    "\n",
    "Remember to:\n",
    "- Convert to float for calculations\n",
    "- Convert back to uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_brightness(image, beta):\n",
    "    \"\"\"Adjust brightness by adding a constant\n",
    "\n",
    "    Args:\n",
    "        image: uint8 image array\n",
    "        beta: brightness adjustment (-255 to 255)\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "def adjust_contrast(image, alpha):\n",
    "    \"\"\"Adjust contrast by multiplication\n",
    "\n",
    "    Args:\n",
    "        image: uint8 image array\n",
    "        alpha: contrast adjustment (0 to 3)\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test your implementation: beta in {50, -50} and alpha in {0.5, 1.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580bdc52",
   "metadata": {},
   "source": [
    "## Exercise 1.3: Working with Image Patches\n",
    "\n",
    "Implement the `extract_patch` function that extracts a rectangular region from an image:\n",
    "- Take center coordinates and patch size as input\n",
    "- Return the extracted patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11dc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patch(image, center, size):\n",
    "    \"\"\"Extract a patch from the image\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        center: (x, y) coordinates of patch center\n",
    "        size: (width, height) of patch\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test your implementation with 100x100 patches centered at: the center of the image, the center of each quadrant (5 patches total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f118c",
   "metadata": {},
   "source": [
    "## Exercise 1.4: Frequency Analysis\n",
    "\n",
    "For each extracted patch:\n",
    "1. Compute the 2D FFT\n",
    "2. Visualize the log magnitude spectrum\n",
    "\n",
    "Questions to consider:\n",
    "- How does the frequency content differ between smooth and detailed regions?\n",
    "- What patterns do you see in the magnitude spectra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e9639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcf78d1",
   "metadata": {},
   "source": [
    "## Exercise 1.5: Homography Estimation\n",
    "\n",
    "1. Understand how the DLT algorithm works\n",
    "3. Test with the provided point correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae14aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_homography_dlt(pts1, pts2):\n",
    "    \"\"\"Estimate homography matrix using DLT\n",
    "\n",
    "    Args:\n",
    "        pts1, pts2: 4x2 arrays of corresponding points\n",
    "    Returns:\n",
    "        H: 3x3 homography matrix mapping pts1 to pts2\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "\n",
    "    # Construct the equations matrix A\n",
    "\n",
    "    # Solve using SVD\n",
    "\n",
    "    # Return normalized homography\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c3b056",
   "metadata": {},
   "source": [
    "The following code will visualize your homography for you - you don't have to modify it, just define correctly the previous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70270c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_homography(img1, img2, H, padding_percent=10):\n",
    "    \"\"\"Verify homography by displaying a visual comparison of two images and their alignment\n",
    "\n",
    "    Args:\n",
    "        img1 (numpy.ndarray): First input image\n",
    "        img2 (numpy.ndarray): Second input image\n",
    "        H (numpy.ndarray): 3x3 homography matrix mapping img1 to img2\n",
    "        padding_percent (int): Amount of padding to add around output image in percent\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Blended result showing alignment of warped img1 with img2\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure images are grayscale\n",
    "    if len(img1.shape) == 3:\n",
    "        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    if len(img2.shape) == 3:\n",
    "        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    h2, w2 = img2.shape[:2]\n",
    "\n",
    "    # Calculate padding\n",
    "    pad_x = int(w2 * padding_percent / 100)\n",
    "    pad_y = int(h2 * padding_percent / 100)\n",
    "\n",
    "    # Create output size with padding\n",
    "    out_w = w2 + 2*pad_x\n",
    "    out_h = h2 + 2*pad_y\n",
    "\n",
    "    # Adjust homography for the padding offset\n",
    "    T = np.array([\n",
    "        [1, 0, pad_x],\n",
    "        [0, 1, pad_y],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    H_adj = T @ H\n",
    "\n",
    "    # Warp and create padded images\n",
    "    img1_warped = cv2.warpPerspective(img1, H_adj, (out_w, out_h))\n",
    "    img2_padded = np.zeros((out_h, out_w), dtype=np.uint8)\n",
    "    img2_padded[pad_y:pad_y+h2, pad_x:pad_x+w2] = img2\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(img1, cmap='gray')\n",
    "    plt.scatter(pts1[:, 0], pts1[:, 1], c='r', s=100)\n",
    "    plt.title('Image 1 with points')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.scatter(pts2[:, 0], pts2[:, 1], c='r', s=100)\n",
    "    plt.title('Image 2 with points')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(133)\n",
    "    blend = cv2.addWeighted(img1_warped, 0.5, img2_padded, 0.5, 0)\n",
    "    plt.imshow(blend, cmap='gray')\n",
    "    plt.title('Blended Result')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return cv2.addWeighted(img1_warped, 0.5, img2_padded, 0.5, 0)\n",
    "\n",
    "# Correspondence points are provided\n",
    "pts1 = np.array([[2023.2, 2350.1], [1408.0, 1536.8],\n",
    "                 [1770.8, 2176.3], [1754.1, 2074.8]])\n",
    "pts2 = np.array([[2982.5, 2398.1], [2354.1, 1538.9],\n",
    "                 [2710.7, 2194.5], [2694.3, 2090.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32038c14",
   "metadata": {},
   "source": [
    "Load the images `grayforest1.jpg` and `grayforest2.jpg` and compute the homography between them using the given correspondence points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edefa95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "# Your code here\n",
    "\n",
    "# Compute the homography using estimate_homography_dlt\n",
    "# Your code here\n",
    "\n",
    "# Visualize results by calling the verify_homography function\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2821ced",
   "metadata": {},
   "source": [
    "# Part 2: Multi-Scale Image Analysis\n",
    "## Exercise 2.1: Convolution and Gaussian Kernels\n",
    "\n",
    "First, implement a basic 2D convolution function:\n",
    "1. Zero padding\n",
    "2. Stride = 1 (simple convolution)\n",
    "3. Test with simple kernels (e.g., blur, edge sharpen, edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdb727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(image, pad):\n",
    "    \"\"\"Add zero padding around the border of an image\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image to pad\n",
    "        pad (int): Number of pixels of padding to add on all sides\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Zero-padded image with original image in center\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "def conv_2d(image, kernel):\n",
    "    \"\"\"Perform 2D convolution of an image with a kernel\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image to convolve\n",
    "        kernel (numpy.ndarray): 2D convolution kernel\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Result of convolving image with kernel\n",
    "\n",
    "    Notes:\n",
    "        Uses zero padding and stride=1\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b2d1d",
   "metadata": {},
   "source": [
    "Now work with Gaussian kernels:\n",
    "\n",
    "We provide a function to create Gaussian kernels. Your tasks:\n",
    "1. Experiment with different kernel sizes and sigma values\n",
    "2. Visualize and analyze how parameters affect the kernel shape\n",
    "3. Consider the implications for image smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb5af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_kernel(size=5, sigma=1.0):\n",
    "    \"\"\"Create a 2D Gaussian kernel for filtering\n",
    "\n",
    "    Args:\n",
    "        size (int): Size of the kernel (must be odd)\n",
    "        sigma (float): Standard deviation of the Gaussian distribution\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Normalized 2D Gaussian kernel of shape (size, size)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If size is not odd\n",
    "    \"\"\"\n",
    "    if size % 2 == 0:\n",
    "        raise ValueError(\"Kernel size must be odd\")\n",
    "\n",
    "    x = np.linspace(-(size//2), size//2, size)\n",
    "    y = x[:, np.newaxis]\n",
    "    kernel = np.exp(-(x*x + y*y)/(2*sigma*sigma))\n",
    "    return kernel / kernel.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e993490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c36047",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Building Gaussian Pyramids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d16f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(image):\n",
    "    \"\"\"Downsample image by factor of 2 using proper averaging\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image to downsample\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Downsampled image at half the input resolution\n",
    "    \"\"\"\n",
    "    return image[::2, ::2]\n",
    "\n",
    "def upsample(image, original_shape):\n",
    "    \"\"\"Upsample image by factor of 2 using linear interpolation\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image\n",
    "        original_shape (tuple): Shape to upsample to\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Upsampled image\n",
    "    \"\"\"\n",
    "    upsampled = np.zeros((image.shape[0]*2, image.shape[1]*2))\n",
    "    upsampled[::2, ::2] = image\n",
    "    # Linear interpolation\n",
    "    upsampled[1::2, ::2] = upsampled[:-1:2, ::2]\n",
    "    upsampled[::2, 1::2] = upsampled[::2, :-1:2]\n",
    "    upsampled[1::2, 1::2] = upsampled[:-1:2, :-1:2]\n",
    "    return upsampled[:original_shape[0], :original_shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134ca8cc",
   "metadata": {},
   "source": [
    "Implement the `build_gaussian_pyramid` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gaussian_pyramid(image, levels=4, kernel_size=5, sigma=1.0):\n",
    "    \"\"\"Build Gaussian pyramid from input image\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image\n",
    "        levels (int): Number of pyramid levels\n",
    "        kernel_size (int): Size of Gaussian kernel\n",
    "        sigma (float): Standard deviation of Gaussian\n",
    "\n",
    "    Returns:\n",
    "        list: Gaussian pyramid levels\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0bf452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a test image\n",
    "# Your code here\n",
    "\n",
    "# Build and visualize Gaussian pyramid for first image\n",
    "gauss_pyramid = build_gaussian_pyramid(image1)\n",
    "\n",
    "# Visualize Gaussian pyramid\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i, level in enumerate(gauss_pyramid):\n",
    "    plt.subplot(1, len(gauss_pyramid), i+1)\n",
    "    plt.imshow(level, cmap='gray')\n",
    "    plt.title(f'Level {i}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Gaussian Pyramid of Image 1')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b87f0",
   "metadata": {},
   "source": [
    "## Exercise 2.3: Laplacian Pyramid\n",
    "\n",
    "Implement functions for:\n",
    "1. Building the Laplacian pyramid\n",
    "2. Reconstructing the original image from the Laplacian pyramid\n",
    "\n",
    "Consider:\n",
    "- How does the Laplacian pyramid represent image details?\n",
    "- What information is captured at each level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df4a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_laplacian_pyramid(gaussian_pyramid):\n",
    "    \"\"\"Build Laplacian pyramid from Gaussian pyramid\n",
    "\n",
    "    Args:\n",
    "        gaussian_pyramid (list): Gaussian pyramid levels\n",
    "\n",
    "    Returns:\n",
    "        list: Laplacian pyramid levels\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "def reconstruct_from_laplacian(laplacian_pyramid):\n",
    "    \"\"\"Reconstruct image from Laplacian pyramid\n",
    "\n",
    "    Args:\n",
    "        laplacian_pyramid (list): Laplacian pyramid levels\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Reconstructed image\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45489bc",
   "metadata": {},
   "source": [
    "Plot the pixel-wise error of the reconstruction using the Laplacian pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f7e83",
   "metadata": {},
   "source": [
    "## Exercise 2.4: Multi-Scale Image Blending\n",
    "\n",
    "Implement the pyramid blending algorithm:\n",
    "1. Build pyramids for both images\n",
    "2. Build pyramid for the mask\n",
    "3. Blend pyramids\n",
    "4. Reconstruct final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid_blend(image1, image2, mask, levels=4):\n",
    "    \"\"\"Blend two images using pyramid blending\n",
    "\n",
    "    Args:\n",
    "        image1, image2 (numpy.ndarray): Images to blend\n",
    "        mask (numpy.ndarray): Blending mask\n",
    "        levels (int): Number of pyramid levels\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Blended image\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287f045b",
   "metadata": {},
   "source": [
    "Demonstrate the pyramid blend on the grayscale images `racoon.jpg` and `crowd.jpg` using the mask provided in `blend_mask.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c52bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f59965",
   "metadata": {},
   "source": [
    "How does the number of levels in the pyramid affect the blending?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa1c4a",
   "metadata": {},
   "source": [
    "# Part 3: Edge Detection\n",
    "## Exercise 3.1: Gradient Computation\n",
    "\n",
    "Implement gradient computation using Sobel operators:\n",
    "1. Define Sobel kernels\n",
    "2. Compute x and y gradients\n",
    "3. Calculate magnitude and direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(image):\n",
    "    \"\"\"Compute gradients using Sobel operators\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image\n",
    "\n",
    "    Returns:\n",
    "        tuple: (gradient magnitude, gradient direction in radians)\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d23d0",
   "metadata": {},
   "source": [
    "## Exercise 3.2: Non-Maximum Suppression\n",
    "\n",
    "Implement non-maximum suppression:\n",
    "1. Convert gradient direction to angles\n",
    "2. Compare magnitude with neighbors along gradient direction\n",
    "3. Suppress non-maximum pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c7cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_maximum_suppression(magnitude, direction):\n",
    "    \"\"\"Apply non-maximum suppression to gradient magnitude\n",
    "\n",
    "    Args:\n",
    "        magnitude (numpy.ndarray): Gradient magnitude\n",
    "        direction (numpy.ndarray): Gradient direction in radians\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Suppressed gradient magnitude\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a318f5db",
   "metadata": {},
   "source": [
    "## Exercise 3.3: Double Thresholding and Edge Tracking\n",
    "\n",
    "Implement:\n",
    "1. Double thresholding to identify strong/weak edges\n",
    "2. Edge tracking by hysteresis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1fee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_threshold(image, low_ratio=0.05, high_ratio=0.15):\n",
    "    \"\"\"Apply double thresholding to classify edges\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image\n",
    "        low_ratio (float): Low threshold ratio\n",
    "        high_ratio (float): High threshold ratio\n",
    "\n",
    "    Returns:\n",
    "        tuple: (strong edges, weak edges)\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "def edge_tracking(strong_edges, weak_edges):\n",
    "    \"\"\"Track edges using hysteresis.\n",
    "\n",
    "    Args:\n",
    "        strong_edges (numpy.ndarray): Binary image of strong edges\n",
    "        weak_edges (numpy.ndarray): Binary image of weak edges\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Final binary edge image\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab493e",
   "metadata": {},
   "source": [
    "## Exercise 3.4: Complete Canny Edge Detector\n",
    "\n",
    "Combine all components into a complete Canny edge detector:\n",
    "1. Gaussian smoothing\n",
    "2. Gradient computation\n",
    "3. Non-maximum suppression\n",
    "4. Double thresholding\n",
    "5. Edge tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa3486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detector(image, kernel_size=5, sigma=1.0,\n",
    "                       low_ratio=0.05, high_ratio=0.15):\n",
    "    \"\"\"Complete Canny edge detection implementation\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image\n",
    "        kernel_size (int): Size of Gaussian kernel\n",
    "        sigma (float): Standard deviation of Gaussian\n",
    "        low_ratio (float): Low threshold ratio\n",
    "        high_ratio (float): High threshold ratio\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing final edges and intermediate results\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    # Return all intermediate results for visualization\n",
    "    return {\n",
    "        'smoothed': smoothed,\n",
    "        'magnitude': magnitude,\n",
    "        'direction': direction,\n",
    "        'suppressed': suppressed,\n",
    "        'strong_edges': strong_edges,\n",
    "        'weak_edges': weak_edges,\n",
    "        'final_edges': final_edges\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31138b67",
   "metadata": {},
   "source": [
    "## Discussion Questions\n",
    "\n",
    "1. How does changing sigma in the Gaussian smoothing affect the detected edges?\n",
    "- How does it impact noise sensitivity?\n",
    "- What happens to fine details as sigma increases?\n",
    "\n",
    "2. Why do we need both gradient magnitude and direction?\n",
    "- What information does each component provide?\n",
    "- How do they work together in edge detection?\n",
    "\n",
    "3. Analyze the role of non-maximum suppression:\n",
    "- What problem does it solve?\n",
    "- How would edges look without it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
